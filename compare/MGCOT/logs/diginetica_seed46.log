/home/guangxu/work/UIO-SBR/compare/MGCOT/main.py:66: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:644.)
  sparse_matrix = torch.sparse.LongTensor(i, v, torch.Size(shape))
Namespace(dataset='diginetica', batchSize=64, hiddenSize=100, epoch=15, lr=0.001, lr_dc=0.1, lr_dc_step=5, l2=1e-05, step=1, patience=3, nonhybrid=False, validation=False, valid_portion=0.1, w_ne=1.7, gama=1.7, seed=46, num_attention_heads=5, neighbor_n=3, contrastive_weight=1.0)
random_seed: 46
self.neighbor: 3
-------------------------------------------------------
epoch:  0
start training:  2026-02-05 21:21:49.286808
contrastive_weight: 1.0
[0/11242] Loss: 23.0111
[2249/11242] Loss: 11.5401
[4498/11242] Loss: 11.0840
[6747/11242] Loss: 9.6846
[8996/11242] Loss: 9.4094
	Loss:	122817.758
start predicting:  2026-02-05 21:38:13.703576
P@5: 38.7377	MRR@5: 22.2296	Epoch: 0,  0
P@10: 48.4226	MRR@10: 23.5289	Epoch: 0,  0
P@20: 57.3236	MRR@20: 24.1505	Epoch: 0,  0
Best Result:
	P@20:	57.3236	MRR@20:	24.1505	Epoch:	0,	0
-------------------------------------------------------
epoch:  1
start training:  2026-02-05 21:39:24.781641
contrastive_weight: 1.0
[0/11242] Loss: 9.0312
[2249/11242] Loss: 8.9337
[4498/11242] Loss: 8.6002
[6747/11242] Loss: 8.5401
[8996/11242] Loss: 7.6827
	Loss:	96165.195
start predicting:  2026-02-05 21:55:22.978288
P@5: 41.0677	MRR@5: 23.2011	Epoch: 1,  1
P@10: 51.7812	MRR@10: 24.6393	Epoch: 1,  1
P@20: 61.9771	MRR@20: 25.3489	Epoch: 1,  1
Best Result:
	P@20:	61.9771	MRR@20:	25.3489	Epoch:	1,	1
-------------------------------------------------------
epoch:  2
start training:  2026-02-05 21:56:34.087748
contrastive_weight: 1.0
[0/11242] Loss: 7.1447
[2249/11242] Loss: 7.9866
[4498/11242] Loss: 8.1786
[6747/11242] Loss: 7.9642
[8996/11242] Loss: 7.7228
	Loss:	91256.570
start predicting:  2026-02-05 22:12:31.304475
P@5: 41.8450	MRR@5: 23.8926	Epoch: 2,  2
P@10: 53.0086	MRR@10: 25.3851	Epoch: 2,  2
P@20: 63.4674	MRR@20: 26.1121	Epoch: 2,  2
Best Result:
	P@20:	63.4674	MRR@20:	26.1121	Epoch:	2,	2
-------------------------------------------------------
epoch:  3
start training:  2026-02-05 22:13:42.405049
contrastive_weight: 1.0
[0/11242] Loss: 7.4084
[2249/11242] Loss: 7.6862
[4498/11242] Loss: 8.2091
[6747/11242] Loss: 8.0719
[8996/11242] Loss: 7.7881
	Loss:	88788.992
start predicting:  2026-02-05 22:29:53.392715
P@5: 41.9156	MRR@5: 24.2629	Epoch: 3,  3
P@10: 53.2732	MRR@10: 25.7887	Epoch: 3,  3
P@20: 63.7172	MRR@20: 26.5154	Epoch: 3,  3
Best Result:
	P@20:	63.7172	MRR@20:	26.5154	Epoch:	3,	3
-------------------------------------------------------
epoch:  4
start training:  2026-02-05 22:31:05.357398
contrastive_weight: 1.0
[0/11242] Loss: 7.1275
[2249/11242] Loss: 7.4610
[4498/11242] Loss: 8.1159
[6747/11242] Loss: 7.5952
[8996/11242] Loss: 7.6831
	Loss:	87085.828
start predicting:  2026-02-05 22:47:28.193483
P@5: 41.9156	MRR@5: 24.2823	Epoch: 3,  4
P@10: 53.2732	MRR@10: 25.8052	Epoch: 3,  4
P@20: 63.8010	MRR@20: 26.5528	Epoch: 4,  4
Best Result:
	P@20:	63.8010	MRR@20:	26.5528	Epoch:	4,	4
-------------------------------------------------------
epoch:  5
start training:  2026-02-05 22:48:38.905164
contrastive_weight: 1.0
[0/11242] Loss: 7.5473
[2249/11242] Loss: 6.8777
[4498/11242] Loss: 7.1165
[6747/11242] Loss: 7.4273
[8996/11242] Loss: 6.9810
	Loss:	78912.633
start predicting:  2026-02-05 23:05:00.573899
P@5: 44.4198	MRR@5: 26.2388	Epoch: 5,  5
P@10: 55.9335	MRR@10: 27.7798	Epoch: 5,  5
P@20: 66.3216	MRR@20: 28.5047	Epoch: 5,  5
Best Result:
	P@20:	66.3216	MRR@20:	28.5047	Epoch:	5,	5
-------------------------------------------------------
epoch:  6
start training:  2026-02-05 23:06:12.613843
contrastive_weight: 1.0
[0/11242] Loss: 6.9791
[2249/11242] Loss: 6.4244
[4498/11242] Loss: 7.2601
[6747/11242] Loss: 6.5467
[8996/11242] Loss: 7.0442
	Loss:	76708.914
start predicting:  2026-02-05 23:22:37.195184
P@5: 44.4198	MRR@5: 26.2564	Epoch: 5,  6
P@10: 55.9335	MRR@10: 27.8291	Epoch: 5,  6
P@20: 66.3216	MRR@20: 28.5551	Epoch: 5,  6
Best Result:
	P@20:	66.3216	MRR@20:	28.5551	Epoch:	5,	6
-------------------------------------------------------
epoch:  7
start training:  2026-02-05 23:23:49.286145
contrastive_weight: 1.0
[0/11242] Loss: 6.2912
[2249/11242] Loss: 6.5862
[4498/11242] Loss: 7.3673
[6747/11242] Loss: 6.8949
[8996/11242] Loss: 7.4327
	Loss:	75839.312
start predicting:  2026-02-05 23:40:12.985250
P@5: 44.4198	MRR@5: 26.2640	Epoch: 5,  7
P@10: 55.9335	MRR@10: 27.8291	Epoch: 5,  6
P@20: 66.3216	MRR@20: 28.5551	Epoch: 5,  6
Best Result:
	P@20:	66.3216	MRR@20:	28.5551	Epoch:	5,	6
-------------------------------------------------------
epoch:  8
start training:  2026-02-05 23:41:25.501504
contrastive_weight: 1.0
[0/11242] Loss: 6.5038
[2249/11242] Loss: 6.6704
[4498/11242] Loss: 6.5766
[6747/11242] Loss: 6.8581
[8996/11242] Loss: 6.3010
	Loss:	75227.727
start predicting:  2026-02-05 23:57:44.737237
P@5: 44.4198	MRR@5: 26.2640	Epoch: 5,  7
P@10: 55.9335	MRR@10: 27.8291	Epoch: 5,  6
P@20: 66.3216	MRR@20: 28.5551	Epoch: 5,  6
Best Result:
	P@20:	66.3216	MRR@20:	28.5551	Epoch:	5,	6
-------------------------------------------------------
epoch:  9
start training:  2026-02-05 23:58:55.419995
contrastive_weight: 1.0
[0/11242] Loss: 7.0040
[2249/11242] Loss: 6.5834
[4498/11242] Loss: 6.3499
[6747/11242] Loss: 6.5216
[8996/11242] Loss: 7.4752
	Loss:	74843.891
start predicting:  2026-02-06 00:15:15.934717
P@5: 44.4198	MRR@5: 26.2640	Epoch: 5,  7
P@10: 55.9335	MRR@10: 27.8291	Epoch: 5,  6
P@20: 66.3216	MRR@20: 28.5551	Epoch: 5,  6
Best Result:
	P@20:	66.3216	MRR@20:	28.5551	Epoch:	5,	6
-------------------------------------------------------
epoch:  10
start training:  2026-02-06 00:16:27.077197
contrastive_weight: 1.0
[0/11242] Loss: 6.8818
[2249/11242] Loss: 6.7694
[4498/11242] Loss: 6.2613
[6747/11242] Loss: 6.2611
[8996/11242] Loss: 6.5925
	Loss:	73285.383
start predicting:  2026-02-06 00:32:48.474955
P@5: 44.4198	MRR@5: 26.2640	Epoch: 5,  7
P@10: 55.9335	MRR@10: 27.8291	Epoch: 5,  6
P@20: 66.3216	MRR@20: 28.5551	Epoch: 5,  6
Best Result:
	P@20:	66.3216	MRR@20:	28.5551	Epoch:	5,	6
-------------------------------------------------------
Run time: 11531.969812 s
Traceback (most recent call last):
  File "/home/guangxu/work/UIO-SBR/compare/MGCOT/main.py", line 181, in <module>
    main()
  File "/home/guangxu/work/UIO-SBR/compare/MGCOT/main.py", line 165, in main
    torch.save(model, PATH)
  File "/home/guangxu/miniconda3/envs/sbr/lib/python3.10/site-packages/torch/serialization.py", line 943, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/guangxu/miniconda3/envs/sbr/lib/python3.10/site-packages/torch/serialization.py", line 810, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/guangxu/miniconda3/envs/sbr/lib/python3.10/site-packages/torch/serialization.py", line 781, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name, _compute_crc32))
RuntimeError: Parent directory ./final_model does not exist.
